{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle, resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from skimage import color, io, transform\n",
    "import pickle\n",
    "class_label = ['Non-Default(0)','Default(1)'] # env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NPY_NUMPY_ALLOWED_HOST_MACHINESIZE'] = str(2 * 1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    492\n",
      "1    492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('D:\\Barath Suresh Docs\\PROGRAMMING\\MACHINE LEARNING\\credit_card_fraud_detection\\creditcard.csv')\n",
    "# Separate the fraud and non-fraud examples\n",
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0]\n",
    "# Random under-sampling of the majority class\n",
    "non_fraud_downsampled = resample(non_fraud, replace=False, n_samples=len(fraud), random_state=42)\n",
    "# Combine minority class with downsampled majority class\n",
    "balanced_df = pd.concat([fraud, non_fraud_downsampled])\n",
    "# Shuffle the examples\n",
    "balanced_df = shuffle(balanced_df, random_state=42)\n",
    "# Print the class distribution of the balanced dataset\n",
    "print(balanced_df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X = df.drop('Class', axis=1).values\n",
    "y = df['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m imgX \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(imgX, \u001b[39m3\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# Convert grayscale to RGB\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Optionally, resize the images to a specific size\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m imgX \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([transform\u001b[39m.\u001b[39;49mresize(x, (\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m3\u001b[39;49m)) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m X])\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(imgX\u001b[39m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[169], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m imgX \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(imgX, \u001b[39m3\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# Convert grayscale to RGB\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# Optionally, resize the images to a specific size\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m imgX \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([transform\u001b[39m.\u001b[39;49mresize(x, (\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m3\u001b[39;49m)) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X])\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(imgX\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\skimage\\transform\\_warps.py:186\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    182\u001b[0m     image \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39mgaussian_filter(image, anti_aliasing_sigma,\n\u001b[0;32m    183\u001b[0m                                 cval\u001b[39m=\u001b[39mcval, mode\u001b[39m=\u001b[39mndi_mode)\n\u001b[0;32m    185\u001b[0m zoom_factors \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m factors]\n\u001b[1;32m--> 186\u001b[0m out \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39;49mzoom(image, zoom_factors, order\u001b[39m=\u001b[39;49morder, mode\u001b[39m=\u001b[39;49mndi_mode,\n\u001b[0;32m    187\u001b[0m                cval\u001b[39m=\u001b[39;49mcval, grid_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m _clip_warp_output(img_bounds, out, mode, cval, clip)\n\u001b[0;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_interpolation.py:774\u001b[0m, in \u001b[0;36mzoom\u001b[1;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[0;32m    771\u001b[0m output_shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m    772\u001b[0m         [\u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(ii \u001b[39m*\u001b[39m jj)) \u001b[39mfor\u001b[39;00m ii, jj \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape, zoom)])\n\u001b[0;32m    773\u001b[0m complex_output \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39miscomplexobj(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 774\u001b[0m output \u001b[39m=\u001b[39m _ni_support\u001b[39m.\u001b[39;49m_get_output(output, \u001b[39minput\u001b[39;49m, shape\u001b[39m=\u001b[39;49moutput_shape,\n\u001b[0;32m    775\u001b[0m                                  complex_output\u001b[39m=\u001b[39;49mcomplex_output)\n\u001b[0;32m    776\u001b[0m \u001b[39mif\u001b[39;00m complex_output:\n\u001b[0;32m    777\u001b[0m     \u001b[39m# import under different name to avoid confusion with zoom parameter\u001b[39;00m\n\u001b[0;32m    778\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_interpolation\u001b[39;00m \u001b[39mimport\u001b[39;00m zoom \u001b[39mas\u001b[39;00m _zoom\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_ni_support.py:78\u001b[0m, in \u001b[0;36m_get_output\u001b[1;34m(output, input, shape, complex_output)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m complex_output:\n\u001b[1;32m---> 78\u001b[0m         output \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mzeros(shape, dtype\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname)\n\u001b[0;32m     79\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m         complex_type \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mpromote_types(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdtype, numpy\u001b[39m.\u001b[39mcomplex64)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "# Normalize the values in the matrix\n",
    "imgX = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "# Reshape the matrix into a 3D array of grayscale images\n",
    "imgX = np.reshape(imgX, (imgX.shape[0], imgX.shape[1], 1))\n",
    "imgX = np.repeat(imgX, 3, axis=2)  # Convert grayscale to RGB\n",
    "# Optionally, resize the images to a specific size\n",
    "imgX = np.array([transform.resize(x, (224, 224, 3)) for x in X])\n",
    "print(imgX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images for use with VGG16\n",
    "imgX = preprocess_input(imgX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 219s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model =  ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "# Remove the last layer of the VGG16 model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an SVM with an RBF kernel as the output layer\n",
    "x = Dense(1, activation='sigmoid', name='svm')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with the modified architecture\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights of the pre-trained VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary crossentropy loss and an Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgX, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 56s 2s/step - loss: 20.6237 - accuracy: 0.5028 - val_loss: 0.9996 - val_accuracy: 0.4684\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 40s 2s/step - loss: 6.1753 - accuracy: 0.5339 - val_loss: 4.4806 - val_accuracy: 0.4684\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 40s 2s/step - loss: 4.1161 - accuracy: 0.5395 - val_loss: 5.4633 - val_accuracy: 0.5316\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 9.8989 - accuracy: 0.5424 - val_loss: 6.3930 - val_accuracy: 0.4684\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 4.4236 - accuracy: 0.5014 - val_loss: 1.0292 - val_accuracy: 0.5949\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 4.4097 - accuracy: 0.5155 - val_loss: 6.1336 - val_accuracy: 0.5316\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 6.4816 - accuracy: 0.4986 - val_loss: 1.1705 - val_accuracy: 0.5949\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 11.1235 - accuracy: 0.5268 - val_loss: 8.5863 - val_accuracy: 0.5316\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 10.6453 - accuracy: 0.4944 - val_loss: 5.7212 - val_accuracy: 0.4684\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 4.5686 - accuracy: 0.5056 - val_loss: 10.4913 - val_accuracy: 0.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15982756310>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 10s 1s/step - loss: 15.6601 - accuracy: 0.4365\n",
      "Accuracy: 0.43654823303222656\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add an SVM kernel layer\n",
    "# svm = SVC(kernel='rbf')\n",
    "# x = svm.fit(x, y_train).support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the new model\n",
    "# model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze the pre-trained layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
